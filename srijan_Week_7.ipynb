{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 1: Regression Task (California Housing)**\n",
        "\n",
        "**Task 1: Load and Split Dataset**"
      ],
      "metadata": {
        "id": "o0WRwR8KEAhw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "_f-JICT-DMwG",
        "outputId": "f906c23d-1a6e-4be7-839d-132ad24314d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/datasets/_base.py:1519: UserWarning: Retry downloading from url: https://ndownloader.figshare.com/files/5976036\n",
            "  warnings.warn(f\"Retry downloading from url: {remote.url}\")\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "HTTP Error 403: Forbidden",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3402342713.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Load dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_california_housing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_X_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Split dataset into training (80%) and test (20%)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/datasets/_california_housing.py\u001b[0m in \u001b[0;36mfetch_california_housing\u001b[0;34m(data_home, download_if_missing, return_X_y, as_frame, n_retries, delay)\u001b[0m\n\u001b[1;32m    175\u001b[0m         )\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         archive_path = _fetch_remote(\n\u001b[0m\u001b[1;32m    178\u001b[0m             \u001b[0mARCHIVE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mdirname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_home\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/datasets/_base.py\u001b[0m in \u001b[0;36m_fetch_remote\u001b[0;34m(remote, dirname, n_retries, delay)\u001b[0m\n\u001b[1;32m   1511\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1513\u001b[0;31m                 \u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1514\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1515\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mURLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0murl_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_splittype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    628\u001b[0m         \u001b[0;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    631\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load dataset\n",
        "X, y = fetch_california_housing(return_X_y=True)\n",
        "\n",
        "# Split dataset into training (80%) and test (20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Shapes\n",
        "print(\"Training features shape:\", X_train.shape)\n",
        "print(\"Test features shape:\", X_test.shape)\n",
        "print(\"Training target shape:\", y_train.shape)\n",
        "print(\"Test target shape:\", y_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 2: Complete all the Task**\n",
        "\n",
        "• Regression Task (California Housing):\n",
        "\n",
        "– Step 1: Baseline Model (No Regularization) Build a Linear Regression model without\n",
        "any regularization.\n",
        "\n",
        "∗ Train the model on the training set.\n",
        "\n",
        "∗ Observe the coefficients of the model.\n",
        "\n",
        "∗ Compute the Mean Squared Error (MSE) on both training and test sets.\n",
        "\n",
        "∗ This step helps to understand how a simple linear model behaves on the dataset and serves as\n",
        "a baseline for comparison."
      ],
      "metadata": {
        "id": "e_e1IpiuSfbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Initialize linear regression model (no regularization)\n",
        "lr = LinearRegression()\n",
        "\n",
        "# Train the model\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# Observe coefficients\n",
        "print(\"Coefficients of Linear Regression:\\n\", lr.coef_)\n",
        "\n",
        "# Predict on training and test sets\n",
        "y_train_pred = lr.predict(X_train)\n",
        "y_test_pred = lr.predict(X_test)\n",
        "\n",
        "# Compute MSE\n",
        "mse_train = mean_squared_error(y_train, y_train_pred)\n",
        "mse_test = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "print(\"Linear Regression MSE (Train):\", mse_train)\n",
        "print(\"Linear Regression MSE (Test):\", mse_test)\n"
      ],
      "metadata": {
        "id": "wCtObmd0HdWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Hyperparameter Tuning Use GridSearchCV or RandomizedSearchCV to tune\n",
        "hyperparameters for Ridge and Lasso regression models.\n",
        "\n",
        "∗ Define a grid of alpha values (regularization strength).\n",
        "\n",
        "∗ Run cross-validation on the training set to find the optimal alpha.\n",
        "\n",
        "∗ Evaluate the model performance on the test set using MSE.\n",
        "\n",
        "∗ This step demonstrates the importance of selecting appropriate hyperparameters to improve\n",
        "generalization."
      ],
      "metadata": {
        "id": "JBw3WTrnSy6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge, Lasso\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define alpha grid\n",
        "alpha_grid = {'alpha': [0.01, 0.1, 1, 10, 100]}\n",
        "\n",
        "# Ridge Regression GridSearch\n",
        "ridge = Ridge()\n",
        "ridge_cv = GridSearchCV(ridge, param_grid=alpha_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "ridge_cv.fit(X_train, y_train)\n",
        "print(\"Best alpha for Ridge:\", ridge_cv.best_params_['alpha'])\n",
        "\n",
        "# Lasso Regression GridSearch\n",
        "lasso = Lasso(max_iter=10000)\n",
        "lasso_cv = GridSearchCV(lasso, param_grid=alpha_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "lasso_cv.fit(X_train, y_train)\n",
        "print(\"Best alpha for Lasso:\", lasso_cv.best_params_['alpha'])\n",
        "\n",
        "# Evaluate on test set\n",
        "ridge_best = Ridge(alpha=ridge_cv.best_params_['alpha'])\n",
        "ridge_best.fit(X_train, y_train)\n",
        "ridge_pred = ridge_best.predict(X_test)\n",
        "\n",
        "lasso_best = Lasso(alpha=lasso_cv.best_params_['alpha'], max_iter=10000)\n",
        "lasso_best.fit(X_train, y_train)\n",
        "lasso_pred = lasso_best.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "print(\"Ridge MSE (Test):\", mean_squared_error(y_test, ridge_pred))\n",
        "print(\"Lasso MSE (Test):\", mean_squared_error(y_test, lasso_pred))\n"
      ],
      "metadata": {
        "id": "S6KFOBwVSscw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Regularization Experiments (L1 vs L2) Train L1 (Lasso) and L2 (Ridge) regres-\n",
        "sion models using the optimal hyperparameters.\n",
        "\n",
        "∗ Compare the coefficients learned by both models. Notice that L1 tends to produce sparse\n",
        "coefficients (some set to zero), while L2 shrinks coefficients without zeroing them.\n",
        "\n",
        "∗ Evaluate and compare the MSE on training and test sets.\n",
        "\n",
        "∗ Discuss the effect of regularization on the bias-variance tradeoff:\n",
        "· How L1/L2 reduces variance and prevents overfitting.\n",
        "· How excessive regularization may increase bias and underfit the data.\n",
        "\n",
        "∗ Visualize the effect by plotting coefficients or training/test error versus alpha values (optional\n",
        "but recommended)."
      ],
      "metadata": {
        "id": "BP69KHH0S481"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Coefficients comparison\n",
        "print(\"Linear Regression Coefficients:\\n\", lr.coef_)\n",
        "print(\"Ridge Coefficients:\\n\", ridge_best.coef_)\n",
        "print(\"Lasso Coefficients:\\n\", lasso_best.coef_)\n",
        "\n",
        "# Observations\n",
        "# - Lasso (L1) produces sparse coefficients (some are zero)\n",
        "# - Ridge (L2) shrinks coefficients but keeps most non-zero\n",
        "# - Regularization reduces variance, prevents overfitting\n",
        "# - Too large alpha can underfit (increase bias)\n"
      ],
      "metadata": {
        "id": "TOgzx4oOS_rS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(lr.coef_, 'o', label='Linear')\n",
        "plt.plot(ridge_best.coef_, 'x', label='Ridge')\n",
        "plt.plot(lasso_best.coef_, 's', label='Lasso')\n",
        "plt.xlabel(\"Feature index\")\n",
        "plt.ylabel(\"Coefficient value\")\n",
        "plt.title(\"Comparison of Coefficients\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0E_H9g0nTFu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 2: Classification Task (Breast Cancer)**\n",
        "\n",
        "Task 1: Load and Split Dataset\n",
        "\n",
        "• Use the Breast Cancer dataset from sklearn.datasets.\n",
        "\n",
        "• Treat it as a binary classification task.\n",
        "\n",
        "• Split into training (80%) and test (20%) sets."
      ],
      "metadata": {
        "id": "0uTKpSm5THu0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "\n",
        "# Split dataset into training (80%) and test (20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Training features shape:\", X_train.shape)\n",
        "print(\"Test features shape:\", X_test.shape)\n"
      ],
      "metadata": {
        "id": "XG7uKmArTTl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 2: Complete all the Task**\n",
        "\n",
        "• Classification Task (Diabetes):\n",
        "\n",
        "– Step 1: Baseline Model (No Regularization) Build a Logistic Regression model without\n",
        "specifying any regularization (default settings).\n",
        "\n",
        "∗ Train the model on the training set.\n",
        "\n",
        "∗ Observe the coefficients of the model.\n",
        "\n",
        "∗ Compute the accuracy on both training and test sets.\n",
        "\n",
        "∗ This step serves as a baseline for comparison and helps to understand the behavior of a standard\n",
        "logistic regression model on the dataset."
      ],
      "metadata": {
        "id": "uB2cVsOCTd0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Logistic Regression (default settings)\n",
        "logreg = LogisticRegression(max_iter=10000)\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# Coefficients\n",
        "print(\"Logistic Regression Coefficients:\\n\", logreg.coef_)\n",
        "\n",
        "# Predict and evaluate accuracy\n",
        "y_train_pred = logreg.predict(X_train)\n",
        "y_test_pred = logreg.predict(X_test)\n",
        "\n",
        "print(\"Accuracy (Train):\", accuracy_score(y_train, y_train_pred))\n",
        "print(\"Accuracy (Test):\", accuracy_score(y_test, y_test_pred))\n"
      ],
      "metadata": {
        "id": "GyfgXQBVTYBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Hyperparameter Tuning Use GridSearchCV or RandomizedSearchCV to tune\n",
        "hyperparameters for logistic regression models with regularization.\n",
        "\n",
        "∗ Focus on tuning the C parameter (inverse of regularization strength) and the penalty type\n",
        "(l1 or l2).\n",
        "\n",
        "∗ Run cross-validation on the training set to identify the optimal hyperparameters.\n",
        "\n",
        "∗ Evaluate the model performance on the test set using accuracy.\n",
        "\n",
        "∗ This step demonstrates the importance of hyperparameter selection for improving model gen-\n",
        "eralization."
      ],
      "metadata": {
        "id": "KBRUoaPkTwmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1','l2'],\n",
        "    'solver': ['liblinear']  # liblinear supports both l1 and l2\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(LogisticRegression(max_iter=10000), param_grid, cv=5, scoring='accuracy')\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters:\", grid.best_params_)\n",
        "\n",
        "# Evaluate on test set\n",
        "best_logreg = grid.best_estimator_\n",
        "y_test_pred = best_logreg.predict(X_test)\n",
        "print(\"Logistic Regression Accuracy (Test):\", accuracy_score(y_test, y_test_pred))\n"
      ],
      "metadata": {
        "id": "TOg9o1p2TlmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Regularization Experiments (L1 vs L2) Train separate logistic regression models\n",
        "using L1 (Lasso-like) and L2 (Ridge-like) regularization with the optimal hyperparameters.\n",
        "\n",
        "∗ Compare the coefficients for L1 and L2. Observe that L1 tends to produce sparse coefficients\n",
        "(some exactly zero), whereas L2 shrinks all coefficients but rarely sets them exactly to zero.\n",
        "\n",
        "∗ Evaluate and compare accuracy on training and test sets.\n",
        "\n",
        "∗ Discuss the effect of regularization on the bias-variance tradeoff:\n",
        "· How L1/L2 reduces variance and mitigates overfitting.\n",
        "· How overly strong regularization may increase bias, reducing accuracy.\n",
        "\n",
        "∗ Optional: Visualize the coefficients or plot accuracy vs C values to better understand the\n",
        "impact of L1 and L2 regularization."
      ],
      "metadata": {
        "id": "GVdbD7s9T6QL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# L1 Regularization\n",
        "logreg_l1 = LogisticRegression(penalty='l1', C=grid.best_params_['C'], solver='liblinear', max_iter=10000)\n",
        "logreg_l1.fit(X_train, y_train)\n",
        "y_test_pred_l1 = logreg_l1.predict(X_test)\n",
        "\n",
        "# L2 Regularization\n",
        "logreg_l2 = LogisticRegression(penalty='l2', C=grid.best_params_['C'], solver='liblinear', max_iter=10000)\n",
        "logreg_l2.fit(X_train, y_train)\n",
        "y_test_pred_l2 = logreg_l2.predict(X_test)\n",
        "\n",
        "# Compare coefficients\n",
        "print(\"L1 Coefficients:\\n\", logreg_l1.coef_)\n",
        "print(\"L2 Coefficients:\\n\", logreg_l2.coef_)\n",
        "\n",
        "# Compare accuracy\n",
        "print(\"Accuracy L1 (Test):\", accuracy_score(y_test, y_test_pred_l1))\n",
        "print(\"Accuracy L2 (Test):\", accuracy_score(y_test, y_test_pred_l2))\n",
        "\n",
        "# Observations:\n",
        "# - L1 produces sparse coefficients (some exactly zero)\n",
        "# - L2 shrinks coefficients but rarely zero\n",
        "# - Regularization reduces variance and overfitting\n",
        "# - Too strong regularization increases bias, reducing accuracy\n"
      ],
      "metadata": {
        "id": "a9AFabDAT3Hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(logreg_l1.coef_[0], 'o', label='L1')\n",
        "plt.plot(logreg_l2.coef_[0], 'x', label='L2')\n",
        "plt.xlabel(\"Feature index\")\n",
        "plt.ylabel(\"Coefficient value\")\n",
        "plt.title(\"L1 vs L2 Coefficients in Logistic Regression\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "DRBQLVpXUCPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QyThhCHPUFlE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}